# Ollama configuration for translation service
Agent:
  service: openai

# Model to use for chat
model: gpt-4o-mini

# Generation parameters
temperature: 0.2
top_p: 1.0
top_k: 40

# You can add more parameters here as needed, such as:
max_tokens: 2048
# stop_sequences: ["\n", "Human:", "AI:"]